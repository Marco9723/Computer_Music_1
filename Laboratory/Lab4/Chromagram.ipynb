{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<h1>Chromagram</h1> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap the concept of Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition of the Discrete STFT\n",
    "\n",
    "We now consider the discrete case of the STFT and specify the most important mathematical formulas as needed in practical applications. \n",
    "\n",
    "Let $x:[0:L-1]:=\\{0,1,\\ldots,L-1\\}\\to{\\mathbb R}$ be a real-valued discrete-time (DT) signal of length $L$ obtained by equidistant sampling with respect to a fixed sampling rate $F_\\mathrm{s}$ given in Hertz. \n",
    "\n",
    "Furthermore, let $w:[0:N-1]\\to\\mathbb{R}$ be a sampled  window function of length $N\\in\\mathbb{N}$. For example, in the case of a rectangular window one has $w(n)=1$ for $n\\in[0:N-1]$. The length parameter $N$ determines the duration of the considered sections, which amounts to $N/F_\\mathrm{s}$ seconds. One also introduces an additional parameter $H\\in\\mathbb{N}$, which is referred to as the **hop size**.  The hop size parameter is specified in samples and determines the step size in which the window is to be shifted across the signal. \n",
    "\n",
    "With regard to these parameters, the **discrete STFT** $\\mathcal{X}$ of the signal $x$ is given by  \n",
    "\n",
    "\\begin{eqnarray}\n",
    "   \\mathcal{X}(m,k):= \\sum_{n=0}^{N-1} x(n+mH)w(n)e^{-2\\pi ikn/N}\n",
    "\\end{eqnarray} \n",
    "\n",
    "with $m\\in[0:M]$ and $k\\in[0:K]$. The number $M:=\\lfloor \\frac{L-N}{H} \\rfloor$ is the maximal frame index such that the window's time range is fully contained in the signal's time range. Furthermore, $K=N/2$ (assuming that $N$ is even) is the frequency index corresponding to the Nyquist frequency. The complex number $\\mathcal{X}(m,k)$ denotes the $k^\\text{th}$ Fourier coefficient for the $m^\\text{th}$ time frame.  Note that for each fixed time frame $m$, one obtains a **spectral vector** of size $K+1$ given by the coefficients $\\mathcal{X}(m,k)$ for $k\\in[0:K]$. The computation of each spectral vector amounts to a DFT of size $N$, which can be done efficiently using the FFT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_basic(x, w, H=8):\n",
    "    \"\"\"Compute a basic version of the discrete short-time Fourier transform (STFT)\n",
    "\n",
    "    Args:\n",
    "        x: Signal to be transformed\n",
    "        w: Window function\n",
    "        H: Hopsize\n",
    "\n",
    "    Returns:\n",
    "        X: The discrete short-time Fourier transform\n",
    "    \"\"\"\n",
    "    N = len(w)\n",
    "    L = len(x)\n",
    "    M = np.floor((L - N) / H).astype(int)\n",
    "    X = np.zeros((N, M + 1), dtype='complex')\n",
    "    for m in range(M + 1):\n",
    "        x_win = x[m * H:m * H + N] * w\n",
    "        X_win = np.fft.fft(x_win)\n",
    "        X[:, m] = X_win\n",
    "    K = (N + 1) // 2\n",
    "    X = X[:K, :]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STFT and Pitch Frequencies\n",
    "\n",
    "Assuming that we are dealing with music whose pitches can be meaningfully categorized according to the equal-tempered scale, we show how an audio recording can be transformed into a feature representation that reveals the distribution of the signal's energy **across the different pitches**. Such features can be obtained from a spectrogram by converting the linear frequency axis (measured in Hertz) into a logarithmic axis (measured in pitches). The resulting representation is also called **log-frequency spectrogram**.\n",
    "\n",
    "We start from the just defined discrete STFT. \n",
    "\n",
    "Let $x$ be a real-valued discrete signal with sampling rate $F_\\mathrm{s}$ (Hertz) and let $\\mathcal{X}$ be the discrete STFT with respect to a window $w$ of length $N\\in\\mathbb{N}$ and hop size $H\\in\\mathbb{N}$. \n",
    "\n",
    "We can assume that the Fourier coefficients $\\mathcal{X}(n,k)$ are indexed by frame parameters $n\\in\\mathbb{Z}$ and frequency parameters $k\\in[0:K]$, where $K=N/2$ is the frequency index corresponding to the Nyquist frequency (zero padding is needed for this assumption). \n",
    "\n",
    "Each Fourier coefficient $\\mathcal{X}(n,k)$ is associated with the physical time position \n",
    "\n",
    "\\begin{equation}\n",
    "T_\\mathrm{coef}(n) = \\frac{n \\cdot H}{F_\\mathrm{s}}\n",
    "\\end{equation}\n",
    "\n",
    "given in seconds and with the physical frequency \n",
    "\n",
    "\\begin{equation}\n",
    "F_\\mathrm{coef}(k) = \\frac{k \\cdot F_\\mathrm{s}}{N}.\n",
    "\\end{equation}\n",
    "\n",
    "The main idea of the log-frequency spectrogram is to **redefine the frequency axis** to correspond to the logarithmically spaced frequency distribution of the equal-tempered scale. Identifying pitches with MIDI note numbers (where the note A4 corresponds to MIDI note number $p=69$), the **center frequencies** are given by:\n",
    "\n",
    "\\begin{equation}\n",
    "F_\\mathrm{MIDI}(p) = 2^{(p-69)/12} \\cdot 440.\n",
    "\\end{equation}\n",
    "\n",
    "As an illustration, we consider a chromatic scale played on a piano starting with the note $A0$ ($p=21$) and ending  with $C8$ ($p=108$). The resulting spectrogram reveals the exponential dependency of the fundamental frequency on the pitches of the played notes. Also, the harmonics and the notes' onset positions (vertical structures) are clearly visible. \n",
    "\n",
    "<img src=\"data/img/chromatic_scale.png\" width=\"500px\" align=\"left\" alt=\"C3\">\n",
    "<br clear=\"all\" />\n",
    "\n",
    "<audio src=\"data/audio/chromatic_scale.wav\" type=\"audio/mpeg\" controls=\"controls\"></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/1867285495.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/2976879287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfn_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'audio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chromatic_scale.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m22050\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_wav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Computation of STFT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "# Load wav\n",
    "fn_wav = os.path.join('data', 'audio', 'chromatic_scale.wav')\n",
    "Fs = 22050\n",
    "x, Fs = librosa.load(fn_wav, sr=Fs)\n",
    "\n",
    "# Computation of STFT\n",
    "N = 4096\n",
    "H = 1024\n",
    "\n",
    "X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann')\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "Y = 20 * np.log10(eps + np.abs(X) ** 2)\n",
    "\n",
    "time_axis = np.arange(X.shape[1]) * H / Fs\n",
    "frequency_axis = np.arange(X.shape[0]) * Fs / N\n",
    "\n",
    "###----------Plot----------###\n",
    "fig = plt.figure(figsize=(21, 7))\n",
    "plt.imshow(Y, origin='lower', aspect='auto', cmap='gray_r', extent=[time_axis[0], time_axis[-1],\n",
    "                                                                    frequency_axis[0], frequency_axis[-1]])\n",
    "plt.clim([-30, 30])\n",
    "plt.ylim([0, 4500])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title('Power spectrogram')\n",
    "\n",
    "# Plot rectangle corresponding to pitch C3 (p=48)\n",
    "rect = matplotlib.patches.Rectangle((29.5, 0.5), 1, 4490, linewidth=2, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect)\n",
    "#plt.text(28.5, -300, r'$\\mathrm{C3}$', color='r', fontsize='x-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Frequency Pooling \n",
    "\n",
    "The logarithmic perception of frequency motivates the use of a time&ndash;frequency representation with a logarithmic frequency axis labeled by the pitches of the equal-tempered scale. \n",
    "\n",
    "To derive such a representation from a given spectrogram representation, the basic idea is to assign each spectral coefficient $\\mathcal{X}(n,k)$ to the pitch with a center frequency that is closest to the frequency $F_\\mathrm{coef}(k)$. More precisely, we define for each pitch $p\\in[0:127]$ the set\n",
    "\n",
    "\\begin{equation}\n",
    "    P(p) := \\{k:F_\\mathrm{MIDI}(p-0.5) \\leq   F_\\mathrm{coef}(k) <  F_\\mathrm{MIDI}(p+0.5)\\}.\n",
    "\\end{equation}\n",
    "\n",
    "The frequency range covered by the set $P(p)$ depends on the frequency in a **logarithmic** fashion. \n",
    "\n",
    "We define the **bandwidth** $\\mathrm{BW}(p)$ of pitch $p$ by \n",
    "\n",
    "\\begin{equation}\n",
    "      \\mathrm{BW}(p):=F_\\mathrm{MIDI}(p+0.5)-F_\\mathrm{MIDI}(p-0.5).\n",
    "\\end{equation}\n",
    "\n",
    "The bandwidth $\\mathrm{BW}(p)$ becomes smaller for decreasing pitches. In particular, it halves when decreasing the pitch by an octave. For example, for MIDI pitch $p=66$ one has a bandwidth of roughly $21.4~\\mathrm{Hz}$, whereas for $p=54$ the bandwidth falls below $10.7~\\mathrm{Hz}$. The following table shows various notes and their MIDI note number $p$, center frequency $F_\\mathrm{MIDI}(p)$, cutoff frequencies $F_\\mathrm{MIDI}(p-0.5)$ and $F_\\mathrm{MIDI}(p+0.5)$, and bandwidth $\\mathrm{BW}(p)$.\n",
    "\n",
    "\n",
    "<img src=\"data/img/midi_to_hz.png\" width=\"700px\" align=\"middle\" alt=\"C0\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Frequency Spectrogram\n",
    "\n",
    "Based on the sets $P(p)$, we obtain a log-frequency spectrogram $\\mathcal{Y}_\\mathrm{LF}:\\mathbb{Z}\\times [0:127]$ using a simple pooling procedure:\n",
    "\n",
    "\\begin{equation}\n",
    "      \\mathcal{Y}_\\mathrm{LF}(n,p) := \\sum_{k \\in P(p)}{|\\mathcal{X}(n,k)|^2}.\n",
    "\\end{equation}\n",
    "\n",
    "By this procedure, the frequency axis is partitioned logarithmically and labeled linearly according to MIDI pitches. The following code example shows the resulting log-frequency spectrogram, where the played notes of the chromatic scale now appear in a linearly increasing fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a reminder\n",
    "\n",
    "\\begin{equation}\n",
    "F_\\mathrm{coef}(k) = \\frac{k \\cdot F_\\mathrm{s}}{N}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "F_\\mathrm{MIDI}(p) = 2^{(p-69)/12} \\cdot 440.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/2550125446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[0mY_LF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF_coef_pitch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_Y_LF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def F_coef(k, Fs, N):\n",
    "    \"\"\"Computes the center frequency/ies of a Fourier coefficient\n",
    "\n",
    "    Args:\n",
    "        k: Fourier coefficient index\n",
    "        Fs: Sampling rate\n",
    "        N: Window size of Fourier fransform\n",
    "\n",
    "    Returns:\n",
    "        im: Frequency value(s)\n",
    "    \"\"\"\n",
    "    return k * Fs / N\n",
    "\n",
    "\n",
    "def F_pitch(p, pitch_ref=69, freq_ref=440):\n",
    "    \"\"\"Computes the center frequency/ies of a MIDI pitch\n",
    "\n",
    "    Args:\n",
    "        p: MIDI pitch value(s)\n",
    "        pitch_ref: Reference pitch (default: 69)\n",
    "        freq_ref: Frequency of reference pitch (default: 440.0)\n",
    "\n",
    "    Returns:\n",
    "        im: Frequency value(s)\n",
    "    \"\"\"\n",
    "    return 2 ** ((p - pitch_ref) / 12) * freq_ref\n",
    "\n",
    "\n",
    "def P(p, Fs, N, pitch_ref=69, freq_ref=440):\n",
    "    \"\"\"Computes the set of frequency indices that are assigned to a given pitch\n",
    "    \n",
    "    Args:\n",
    "        p: MIDI pitch value\n",
    "        Fs: Sampling rate\n",
    "        N: Window size of Fourier fransform\n",
    "        pitch_ref: Reference pitch (default: 69)\n",
    "        freq_ref:  Frequency of reference pitch (default: 440.0)\n",
    "\n",
    "    Returns:\n",
    "        im: Set of frequency indices\n",
    "    \"\"\"\n",
    "    lower = F_pitch(p - 0.5, pitch_ref, freq_ref)\n",
    "    upper = F_pitch(p + 0.5, pitch_ref, freq_ref)\n",
    "    k = np.arange(N // 2 + 1)\n",
    "    k_freq = F_coef(k, Fs, N)\n",
    "    mask = np.logical_and(lower <= k_freq, k_freq < upper)\n",
    "    return k[mask]\n",
    "\n",
    "\n",
    "def compute_Y_LF(Y, Fs, N):\n",
    "    \"\"\"Computes a log-frequency spectrogram\n",
    "\n",
    "    Args:\n",
    "        Y: Magnitude or power spectrogram\n",
    "        Fs: Sampling rate\n",
    "        N: Window size of Fourier fransform\n",
    "        pitch_ref: Reference pitch (default: 69)\n",
    "        freq_ref: Frequency of reference pitch (default: 440.0)\n",
    "\n",
    "    Returns:\n",
    "        Y_LF: Log-frequency spectrogram\n",
    "        F_coef_pitch: Pitch values\n",
    "    \"\"\"\n",
    "    Y_LF = np.zeros((128, Y.shape[1]))\n",
    "    for p in range(128):\n",
    "        k = P(p, Fs, N)\n",
    "        Y_LF[p, :] = Y[k, :].sum(axis=0)\n",
    "    F_coef_pitch = np.arange(128)    \n",
    "    return Y_LF, F_coef_pitch\n",
    "\n",
    "\n",
    "Y = np.abs(X) ** 2\n",
    "Y_LF, F_coef_pitch = compute_Y_LF(Y, Fs, N)        \n",
    "\n",
    "time_axis = np.arange(X.shape[1]) * H / Fs\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "eps = np.finfo(float).eps\n",
    "plt.imshow(20 * np.log10(eps + Y_LF), origin='lower', aspect='auto', cmap='gray_r', extent=[time_axis[0],\n",
    "                                                                                            time_axis[-1], 0, 127])\n",
    "plt.clim([-20, 80])\n",
    "plt.ylim([21, 108])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (pitch)')\n",
    "plt.title('Log frequency power spectrogram')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a Rectangle patch\n",
    "rect = matplotlib.patches.Rectangle((29.5, 21), 1, 86.5, linewidth=2, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect)\n",
    "plt.text(28.5, 15, r'$\\mathrm{C3}$', color='r', fontsize='x-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the spectrogram visualization, one can make some interesting observations:\n",
    "\n",
    "* As a general trend, the sounds for higher notes possess a cleaner harmonic spectrum than the ones for lower notes. For lower notes, the signal's energy is often contained in the higher harmonics, while the listener may still have the perception of a low-pitched sound. \n",
    "\n",
    "* The vertical stripes (along the frequency axis) shown by the spectrogram indicate that some of the signal's energy is spread over large parts of the spectrum. The main reason for the energy spread is due to the inharmonicities of the piano sound caused by the keystroke (mechanical noise) as well as transient and resonance effects. \n",
    "\n",
    "* Furthermore, the frequency content of a sound depends on the microphone's frequency response. For example, the microphone may capture only frequencies above a certain threshold as in the case of our audio example. This also may explain why there is virtually no energy visible in the fundamental frequencies for the notes $A0$ ($p=21$) to $B0$ ($p=32$).\n",
    "\n",
    "Besides acoustic properties, there is another reason for the rather poor representation of low pitches when using the pooling strategy based on a discrete STFT. While the discrete STFT introduces a **linear** sampling of the frequency axis, the bandwidth used in the pooling strategy depends on the frequency in a **logarithmic** fashion. As a result, the set $P(p)$ may contain only very few spectral coefficients or may even be empty for small values of $p$ (which is the reason for the horizontal white stripes in the figure above). This is also demonstrated by the following code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: Fs =  22050\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/1580742490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sampling rate: Fs = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Window size: N = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'STFT frequency resolution (in Hz): Fs/N = %4.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m52\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m39\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m38\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "print('Sampling rate: Fs = ', Fs)\n",
    "print('Window size: N = ', N)\n",
    "print('STFT frequency resolution (in Hz): Fs/N = %4.2f' % (Fs / N))\n",
    "\n",
    "for p in [76, 64, 52, 40, 39, 38]:\n",
    "    print('Set P(%d) = %s' % (p, P(p, Fs, N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resolve the issues of having an insufficient frequency resolution (in particular for low pitches), one may use a larger STFT window (at the cost of loosing time resolution). An alternative may be the usage of **interpolation techniques** or frequency refinement techniques based on **instantaneous frequency estimation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chromagram\n",
    "\n",
    "We now discuss a strategy to increase the robustness of the log-frequency spectrogram to variations in timbre and instrumentation. The main idea is to suitably combine pitch bands corresponding to pitches that differ by one or several octaves. The human perception of pitch is periodic in the sense that two pitches are perceived as similar in \"color\" (playing a similar harmonic role) if they differ by an **octave**. \n",
    "\n",
    "Based on this observation, a pitch can be separated into two components, which are referred to as **tone height** and **chroma**. The tone height refers to the octave number and the chroma to the respective pitch spelling attribute contained in the set \n",
    "\n",
    "$$\n",
    "\\{\\mathrm{C},\\mathrm{C}^\\sharp,\\mathrm{D},\\mathrm{D}^\\sharp,\\ldots,\\mathrm{B}\\}.\n",
    "$$\n",
    "\n",
    "Enumerating the chroma values, we identify this set with $[0:11]$ where $0$ refers to chroma $\\mathrm{C}$, $1$ to $\\mathrm{C}^\\sharp$, and so on. A **pitch class** is defined as the set of all pitches that share the same chroma. For example, the pitch class corresponding to the chroma  $\\mathrm{C}$ is the set  $\\{\\ldots,\\,\\mathrm{C0},\\mathrm{C1},\\mathrm{C2},\\mathrm{C3},\\ldots\\}$ consisting of all pitches separated by an integer number of octaves. For simplicity, we use the terms chroma and pitch class interchangeably.\n",
    "\n",
    "The main idea of **chroma features** is to aggregate all spectral information that relates to a given pitch class into a single coefficient. Given a pitch-based log-frequency spectrogram $\\mathcal{Y}_\\mathrm{LF}:\\mathbb{Z}\\times[0:127]\\to \\mathbb{R}_{\\geq 0}$, a **chroma representation** or **chromagram** $\\mathbb{Z}\\times[0:11]\\to \\mathbb{R}_{\\geq 0}$ can be derived by summing up all pitch coefficients that belong to the same chroma:\n",
    "\n",
    "\\begin{equation}\n",
    "      \\mathcal{C}(n,c) := \\sum_{\\{p \\in [0:127]\\,:\\,p\\,\\mathrm{mod}\\,12 = c\\}}{\\mathcal{Y}_\\mathrm{LF}(n,p)}\n",
    "\\end{equation}\n",
    "\n",
    "for $c\\in[0:11]$. Continuing our example, the following code example generates a chromagram of the chromatic scale, where the cyclic nature of chroma features becomes evident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_LF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/2635583617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_chromagram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_LF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_LF' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_chromagram(Y_LF):\n",
    "    \"\"\"Computes a chromagram\n",
    "\n",
    "    Args:\n",
    "        Y_LF: Log-frequency spectrogram\n",
    "\n",
    "    Returns:\n",
    "        C: Chromagram\n",
    "    \"\"\"\n",
    "    C = np.zeros((12, Y_LF.shape[1]))\n",
    "    p = np.arange(128)\n",
    "    for c in range(12):\n",
    "        mask = (p % 12) == c\n",
    "        C[c, :] = Y_LF[mask, :].sum(axis=0)\n",
    "    return C\n",
    "\n",
    "C = compute_chromagram(Y_LF)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "time_axis = np.arange(X.shape[1]) * H / Fs\n",
    "\n",
    "chroma_label = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "plt.imshow(20 * np.log10(eps + C), origin='lower', aspect='auto', cmap='gray_r', extent=[time_axis[0], \n",
    "                                                                                         time_axis[-1], 0, 12])\n",
    "plt.clim([0, 100])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.title('Chromagram')\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(12) + 0.5, chroma_label)\n",
    "plt.tight_layout()\n",
    "\n",
    "rect = matplotlib.patches.Rectangle((29.5, 0.0), 1, 12, linewidth=2, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect)\n",
    "plt.text(28.5, -1.2, r'$\\mathrm{C3}$', color='r', fontsize='x-large');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the octave equivalence, the increasing notes of the chromatic scale are \"wrapped around\" the chroma axis. As with the log-frequency spectrogram, the resulting chromagram of the considered audio example is rather noisy, in particular for the lower notes. \n",
    "\n",
    "Furthermore, because of the presence of higher harmonics, the energy is typically spread across various chroma bands even when playing a single note at a time. For example, playing the note $\\mathrm{C3}$, the third harmonic corresponds to $\\mathrm{G4}$ and the fifth harmonic to $\\mathrm{E5}$.  Therefore, when playing the note $\\mathrm{C3}$ on the piano, not only the chroma band $\\mathrm{C}$, but also the chroma bands $\\mathrm{G}$ and $\\mathrm{E}$ contain a substantial portion of the signal's energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Burgmüller\n",
    "\n",
    "\n",
    "As an illustrating example, we now consider the first four measures of Op. 100, No. 2 by Friedrich Burgmüller. In the lower staff of the score (left hand), one can see that the chord consisting of the three notes $\\mathrm{A3}$ ($p=57$), $\\mathrm{C4}$ ($p=60$), and $\\mathrm{E4}$ ($p=64$) is played every quarter beat&mdash;altogether eight times over the first four measures. These chords are also clearly visible in the the log-frequency spectrogram and chromagram shown below. Furthermore, the patterns resulting from the two sixteenth-note phrases (upper staff of the score, right hand) are clearly revealed. Looking at the visualizations, it is important to note that **inharmonicities** and **partials** may result in substantial contributions in certain frequency and chroma bands not relating to the fundamental frequencies of the notes shown in the score. Another important issue is the imperfection of the Fourier analysis, also known as **spectral leakage**, which is the result of the frequency smearing introduced by the window function. \n",
    "\n",
    "<img src=\"data/img/burgmuller.png\" width=\"500px\" align=\"left\" alt=\"C1\">\n",
    "\n",
    "<br clear=\"all\" />\n",
    "\n",
    "<audio src=\"data/audio/burgmuller.wav\" type=\"audio/mpeg\" controls=\"controls\"></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19136/1957719944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfn_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'audio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'burgmuller.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_wav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# ipd.display(ipd.Audio(x, rate=Fs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4096\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "fn_wav = os.path.join('data', 'audio', 'burgmuller.wav')\n",
    "x, Fs = librosa.load(fn_wav)\n",
    "# ipd.display(ipd.Audio(x, rate=Fs))\n",
    "\n",
    "N = 4096\n",
    "H = 512\n",
    "w = scipy.signal.get_window('hann', N)\n",
    "X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window=w, pad_mode='constant')\n",
    "t = librosa.frames_to_time(np.arange(X.shape[1]), sr=Fs, hop_length=H, n_fft=N)\n",
    "freq = librosa.fft_frequencies(sr=Fs, n_fft=N)\n",
    "\n",
    "Y = np.abs(X) ** 2\n",
    "Y_LF, F_coef_pitch = compute_Y_LF(Y, Fs, N)\n",
    "C = compute_chromagram(Y_LF)\n",
    "\n",
    "###----------Plot----------###\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.imshow(20 * np.log10(eps + Y_LF), origin='lower', aspect='auto', cmap='gray_r', extent=[t[0], t[-1], 0, 128])\n",
    "plt.clim([20, 80])\n",
    "plt.ylim([55, 92])\n",
    "plt.title('Log-frequency power spectrogram')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (pitch)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 3))\n",
    "plt.imshow(20 * np.log10(eps + C), origin='lower', aspect='auto', cmap='gray_r', extent=[t[0], t[-1], 0, 12])\n",
    "plt.clim([20, 80])\n",
    "plt.title('Chromagram')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Chroma')\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(12) + 0.5, chroma_label)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
