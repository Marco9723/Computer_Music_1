{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onset detection\n",
    "## Musical Onsets\n",
    "\n",
    "The notion of a musical onset can be rather vague and is related to other concepts such as attacks or transients. When playing a note on an instrument such as a piano, there is often a sudden increase of energy at the beginning of a musical tone. The **attack** of a note refers to the phase where the sound builds up, which typically goes along with a sharply increasing amplitude envelope. The related concept of a **transient** refers to a noise-like sound component of short duration and high amplitude typically occurring at the beginning of a musical tone or a more general sound event. As opposed to the attack and transient, the **onset** of a note refers to the single instant (rather than a period) that marks the beginning of the transient, or the earliest time point at which the transient can be reliably detected. This is illustrated by the following figure.\n",
    "\n",
    "<img src=\"img/otad.png\" width=\"320px\" align=\"middle\" alt=\"Attack, transient, decay and onset for a single note\">\n",
    "\n",
    "Intuitively speaking, **onset detection** is the task of determining the starting times of notes or other musical events as they occur in a music recording. To detect note onsets in the signal, the general idea is to capture sudden changes that often mark the beginning of transient regions. For notes that have a pronounced attack phase, onset candidates may be determined by locating time positions where the signal's amplitude envelope starts increasing. In the following figure, we show the waveform and the spectrogram of a click sound as well as of a piano sound (playing the note $\\mathrm{C4}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/2561771651.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# we need to install matplotlib with conda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m  \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "# we need to install matplotlib with conda\n",
    "from  matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "def load_and_plot_wav(fn_wav, display_audio=True):\n",
    "    x, Fs = librosa.load(fn_wav, sr=None) \n",
    "    plt.figure(figsize=(10,4))\n",
    "     \n",
    "    time_axis = np.arange(x.shape[0]) / Fs\n",
    "    plt.plot(time_axis, x)\n",
    "    plt.xlim([time_axis[0], time_axis[-1]])\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Waveform')\n",
    "    if display_audio == True:\n",
    "        ipd.display(ipd.Audio(x, rate=Fs))\n",
    "    return x, Fs\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram(x, Fs):\n",
    "    N, H = 512, 256 \n",
    "    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hanning')\n",
    "    Y = np.log(1 + 10 * np.abs(X))\n",
    "    \n",
    "    time_axis = np.arange(X.shape[1]) / (Fs / H)\n",
    "    frequency_axis = np.arange(X.shape[0]) / (N / Fs)\n",
    "    \n",
    "    x_ext = (time_axis[1] - time_axis[0]) / 2\n",
    "    y_ext = (frequency_axis[1] - frequency_axis[0]) / 2\n",
    "    image_extent = [time_axis[0]-x_ext, time_axis[-1]+x_ext, frequency_axis[0]-y_ext, frequency_axis[-1]-y_ext]\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.imshow(Y, extent=image_extent, aspect='auto', origin='lower')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    \n",
    "fn_wav = os.path.join('audio', 'Impulse.wav')\n",
    "x, Fs = load_and_plot_wav(fn_wav)\n",
    "plot_spectrogram(x, Fs)\n",
    "\n",
    "fn_wav = os.path.join('audio', 'NoteC4_Piano.wav')\n",
    "x, Fs = load_and_plot_wav(fn_wav)\n",
    "plot_spectrogram(x, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no clear attack phase, such as for nonpercussive music with soft onsets and blurred note transitions, the detection of onsets is much more challenging. For example, the waveform of a violin sound may exhibit a slow energy increase rather than an abrupt change as in a piano sound. For soft sounds, it is hard to determine or even to define the exact onset position. This is illustrated by the violin example (sound of $\\mathrm{C4}$) of the next figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = os.path.join('audio', 'NoteC4_Violin.wav')\n",
    "x, Fs = load_and_plot_wav(fn_wav)\n",
    "plot_spectrogram(x, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detection of individual note onsets becomes even harder when dealing with complex polyphonic music. Simultaneously occurring sound events may result in masking effects, where no significant changes in the signal's energy are measurable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = os.path.join('audio', 'Audio_Borodin-sec39_RWC.wav')\n",
    "x, Fs = load_and_plot_wav(fn_wav)\n",
    "plot_spectrogram(x, Fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Pipeline\n",
    "\n",
    "Many approaches for onset detection follow a similar algorithmic pipeline, but differ in the signal properties that are exploited to derive onset candidates. In this pipeline, the main steps are as follows:\n",
    "\n",
    "* First, the signal is converted into a suitable feature representation that better reflects the properties of interest. \n",
    "* Then, a type of derivative operator is applied to the feature sequence and a **novelty function** is derived. \n",
    "* Finally, a peak-picking algorithm is employed to locate the onset candidates.\n",
    "\n",
    "\n",
    "<img src=\"img/onsetdetection_pipeline.png\"  width=\"500\" align=\"middle\" alt=\"Onset detection architecture\">\n",
    "\n",
    "\n",
    "\n",
    "In particular, we show how to transform a given music signal into a **novelty representation** that captures certain changes in the signal's energy or spectrum. The peaks of such a representation yield good indicators for note onset candidates. We will see a similar concept when applying novelty detection to music structure analysis. \n",
    "\n",
    "There are four different approaches for computing novelty functions:\n",
    "\n",
    "* **Energy-based novelty** approaches measure changes in the flow of the signal's local energy\n",
    "\n",
    "* **Spectral-based novelty** approaches measure changes of the signal's spectral content over time.\n",
    "\n",
    "* **Phase-based novelty** approaches measure indicate discontinuities in the signal's phase spectrum.\n",
    "\n",
    "* **Complex-domain novelty** approaches combine spectral-based and phase-based information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Another One Bites the Dust\n",
    "  \n",
    "As an illustrative example, we consider an excerpt of \"Another one bites the dust\" by Queen. Starting with an offbeat consisting of two sixteenth notes played only by bass, four percussive beats (played by kick drum, snare drum, hihat, and bass) follow. Furthermore, between each two subsequent beats, there is an additional hihat stroke. The subsequent figure shows the waveform with annotated onset positions. \n",
    "\n",
    "<img src=\"img/Queen.png\" width=\"350px\" align=\"left\" alt=\"Queen\">\n",
    "\n",
    "<br clear=\"all\" />\n",
    "\n",
    "<audio style=\"width: 320px;\" src=\"audio/Queen.wav\" type=\"audio/mpeg\" controls=\"controls\"></audio>\n",
    "\n",
    "The following spectrogram representation shows, that the quarter-note drum beats as well as the hihat sounds go along with transients (vertical lines), while the initial two bass-only sounds have more diffuse onset properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_plot_wav' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/1371171474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfn_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'audio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Queen.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_and_plot_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_wav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplot_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_and_plot_wav' is not defined"
     ]
    }
   ],
   "source": [
    "fn_wav = os.path.join('audio', 'Queen.wav')\n",
    "\n",
    "x, Fs = load_and_plot_wav(fn_wav)\n",
    "plot_spectrogram(x, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we use a spectral-based method for computing a novelty function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_average(x, M, Fs=1):\n",
    "    \"\"\"Compute local average of signal\n",
    "\n",
    "    Args:\n",
    "        x: Signal\n",
    "        M: Determines size (2M+1*Fs) of local average\n",
    "        Fs: Sampling rate\n",
    "\n",
    "    Returns:\n",
    "        local_average: Local average signal\n",
    "    \"\"\"\n",
    "    L = len(x)\n",
    "    M = int(np.ceil(M * Fs))\n",
    "    local_average = np.zeros(L)\n",
    "    for m in range(L):\n",
    "        a = max(m - M, 0)\n",
    "        b = min(m + M + 1, L)\n",
    "        local_average[m] = (1 / (2 * M + 1)) * np.sum(x[a:b])\n",
    "    return local_average\n",
    "\n",
    "\n",
    "def a_method_for_novelty(x, Fs=1, N=1024, H=256, gamma=100, M=10, norm=1):\n",
    "    \"\"\"Compute spectral-based novelty function\n",
    "    \"\"\"\n",
    "    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hanning')\n",
    "    Fs_feature = Fs / H\n",
    "    Y = np.log(1 + gamma * np.abs(X))\n",
    "    Y_diff = np.diff(Y)\n",
    "    Y_diff[Y_diff < 0] = 0\n",
    "    novelty_spectrum = np.sum(Y_diff, axis=0)\n",
    "    novelty_spectrum = np.concatenate((novelty_spectrum, np.array([0.0])))\n",
    "    if M > 0:\n",
    "        local_average = compute_local_average(novelty_spectrum, M)\n",
    "        novelty_spectrum = novelty_spectrum - local_average\n",
    "        novelty_spectrum[novelty_spectrum < 0] = 0.0\n",
    "    if norm == 1:\n",
    "        max_value = max(novelty_spectrum)\n",
    "        if max_value > 0:\n",
    "            novelty_spectrum = novelty_spectrum / max_value\n",
    "    return novelty_spectrum, Fs_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = [0.117460317, 0.247619048, 0.646349206, 1.184761905, 1.735238095, 2.287619048]\n",
    "beats = [0.372698413, 0.911111111, 1.445442177,  2.000000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/1205920299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfn_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'audio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Queen.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_wav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs_nov\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0ma_method_for_novelty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "fn_wav = os.path.join('audio', 'Queen.wav')\n",
    "x, Fs = librosa.load(fn_wav)\n",
    "\n",
    "nov, Fs_nov =a_method_for_novelty(x, Fs=Fs)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "nov_time_axis = np.arange(nov.shape[0]) / Fs_nov\n",
    "plt.plot(nov_time_axis, nov)\n",
    "\n",
    "\n",
    "for b in beats:\n",
    "    plt.axvline(b, color='red')\n",
    "    \n",
    "for o in onsets:\n",
    "    plt.axvline(o, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply a peak picking strategy to locate the **local maxima** or **peaks** of the novelty function. The positions of the peaks are our candidates for onset positions. In the following code, cell we apply a peak picking strategy provided by the function [`scipy.signal.find_peaks`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html). In the following cell, we generate a visualization of the peaks along with a **sonification** via a click track added to the original audio recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/2322518593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpeaks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproperties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprominence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpeaks_sec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnov_time_axis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nov' is not defined"
     ]
    }
   ],
   "source": [
    "peaks, properties = signal.find_peaks(nov, prominence=0.2)\n",
    "peaks_sec = nov_time_axis[peaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/3452388393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnov_time_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbeats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(nov_time_axis, nov, color='blue')\n",
    "\n",
    "for b in beats:\n",
    "    plt.axvline(b, color='red')\n",
    "    \n",
    "for o in onsets:\n",
    "    plt.axvline(o, color='red', linestyle='--')\n",
    "    \n",
    "plt.scatter(peaks_sec, nov[peaks], marker='o', color='red' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9360/4071531345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m x_peaks = librosa.clicks(peaks_sec, sr=Fs, click_freq=1000, \n\u001b[0m\u001b[0;32m      2\u001b[0m                          length=len(x))\n\u001b[0;32m      3\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx_peaks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "x_peaks = librosa.clicks(peaks_sec, sr=Fs, click_freq=1000, \n",
    "                         length=len(x))\n",
    "ipd.display(ipd.Audio( x + 0.5*x_peaks, rate=Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
