{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1>Template-Based Chord Recognition</h1> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical chord recognition system consists of two main steps. In the first step, the given audio recording is cut into frames, and each frame is transformed into an appropriate feature vector. Most recognition systems rely on chroma-based audio features, which correlate to the underlying tonal information contained in the audio signal. \n",
    "\n",
    "\n",
    "In the second step, pattern matching techniques are used to map each feature vector to a set of predefined chord models. The best fit determines the chord label assigned to the given frame. \n",
    "\n",
    "To improve the chord recognition results, additional enhancement techniques are applied either before the pattern matching step (referred to as **prefiltering**) or after/within the pattern matching step \n",
    "(referred to as **postfiltering**). In this notebook, we introduce a first chord recognition procedure that employs a simple template-based matching strategy.\n",
    "\n",
    "<img src=\"data/img/chord_rec_architecture.png\" width=\"500px\" align=\"middle\" alt=\"chord recognition\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalization of the Chord Recognition Problem\n",
    "\n",
    "Given an audio recording of a piece of music, the goal of our chord recognition task is to find out which chords are played at which time.  The first step is to transform the recording into a sequence $X=(x_1,x_2,\\ldots,x_N)$ of feature vectors $x_n\\in\\mathcal{F}$, $n\\in[1:N]$, where $\\mathcal{F}$ denotes a suitable feature space. Then, each feature vector $x_n$ is to be mapped to a chord label $\\lambda_{n} \\in \\Lambda$, where $\\Lambda$ denotes a set of possible chord labels. For example, one may consider the set\n",
    "\n",
    "\\begin{equation}\n",
    "  \\Lambda = \\{\\mathbf{C},\\mathbf{C}^\\sharp,\\ldots,\\mathbf{B},\\mathbf{Cm},\\mathbf{Cm^\\sharp},\\ldots,\\mathbf{Bm}\\}\n",
    "\\end{equation}\n",
    "\n",
    "consisting of the twelve major and minor triads. In this case, each frame $n\\in[1:N]$ is assigned to a major chord or a minor chord specified by $\\lambda_{n}$. \n",
    "\n",
    "For the feature extraction step, basically every chord recognition procedure relies on some type of chroma features. This is because chroma-based features capture a signal's short-time tonal content,\n",
    "which is closely correlated to the harmonic progression of the underlying piece. Assuming the equal-tempered scale, the chroma values correspond to the set $\\{\\mathrm{C},\\mathrm{C}^\\sharp,\\mathrm{D},\\ldots,\\mathrm{B}\\}$, which we identify with the set $[0:11]$. A chroma feature can then be expressed as a $12$-dimensional vector $x=(x(0),x(1),\\ldots,x(11))^\\top\\in\\mathcal{F}$ with $\\mathcal{F}=\\mathbb{R}^{12}$.\n",
    "\n",
    "In the following example, the chord recognition task is illustrated by the first measures of The Beatles' song \"Let It Be.\" As for the chroma representation, a window size that corresponds to $200$ msec and a hop size of half the window length is used. As a result, our feature sequence $X=(x_1,x_2,\\ldots,x_N)$ has a feature rate of $10$ Hz. The chord recognition result is obtained in a frame-wise fashion, where subsequent frames with the same chord label are visualized as a single labeled segments.  \n",
    "\n",
    "<img src=\"data/img/chord_example.png\" width=\"500px\" align=\"center\" alt=\"example of chord recognition\">\n",
    "\n",
    "<br clear=\"all\" />\n",
    "\n",
    "<audio style=\"width: 400px;\" src=\"data/audio/Beatles_LetItBe.wav\" type=\"audio/mpeg\" controls=\"controls\"></audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template-Based Pattern Matching\n",
    "\n",
    "For the pattern matching step, we now introduce a simple template-based approach. The idea is to precompute a set $\\mathcal{T}\\subset\\mathcal{F}=\\mathbb{R}^{12}$ of templates denoted by $\\mathbf{t}_\\lambda\\in\\mathcal{T}$, $\\lambda\\in\\Lambda$.\n",
    "Intuitively, each template can be thought of as a prototypical chroma \n",
    "vector that represents a specific musical chord.\n",
    "Furthermore, we fix a similarity measure \n",
    "\n",
    "\\begin{equation}\n",
    "s:\\mathcal{F}\\times\\mathcal{F}\\to \\mathbb{R}\n",
    "\\end{equation}\n",
    "\n",
    "that allows for comparing different chroma vectors. Then, the template-based procedure consists in assigning the chord label that maximizes the similarity between the corresponding template and the given feature vector $x_n$:\n",
    "\n",
    "\\begin{equation}\n",
    "        \\lambda_{n} := \\underset{\\lambda \\in \\Lambda}{\\mathrm{argmax}}\n",
    "         \\,\\, s( \\mathbf{t}_\\lambda , x_n ).\n",
    "\\end{equation}\n",
    "\n",
    "In this procedure, there are many design choices that crucially influence the performance of a chord recognizer. Which chords should be considered in $\\mathcal{T}$? How are the chord templates defined?  What is a suitable similarity measure to compare the feature vectors with the chord templates? \n",
    "\n",
    "To obtain a first simple chord recognition system, we make the following design choices. \n",
    "\n",
    "For the **chord label set** $\\Lambda$, we choose the twelve major and minor triads. This choice, even though problematic from a musical point of view, is convenient and instructive. Considering chords up to enharmonic equivalence and up to octave shifts, each triad can be encoded by a three-element subset of $[0:11]$. For example, the $\\mathrm{C}$ major chord $\\mathbf{C}$ corresponds tto the subset $\\{0,4,7\\}$. Each subset, in turn, can be identified with a binary twelve-dimensional chroma vector $x=(x(0),x(1),\\ldots,x(11))^\\top$, where $x(i)=1$ if and only if the chroma value $i\\in[0:11]$ is contained in the chord. For example, in the case of the $\\mathrm{C}$ major chord $\\mathbf{C}$, the resulting chroma vector is\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:ChordReco:Template:Basic:ChromaVectC}\n",
    "    \\mathbf{t}_{\\mathbf{C}}{} := x =(1,0,0,0,1,0,0,1,0,0,0,0)^\\top\n",
    "\\end{equation}\n",
    "\n",
    "Using a chroma-based encoding, the twelve major chords and twelve minor chords can be obtained by cyclically shifting the binary vectors for the $\\mathrm{C}$ major and the $\\mathrm{C}$ minor triads, respectively. The result is illustrated by the following figure.\n",
    "\n",
    "<img src=\"data/img/templates.png\" width=\"800px\" align=\"middle\" alt=\"FMP_C5_F06\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For comparing chroma features and chord templates, we use in the following a simple **similarity measure** using the inner product of normalized vectors:\n",
    "\n",
    "\\begin{equation}\n",
    "  s(x,y)= \\frac{\\langle x,y\\rangle}{||x||\\cdot||y||}\n",
    "\\end{equation}\n",
    "\n",
    "for $x,y\\in\\mathcal{F}\\setminus\\{0\\}$. In the case $||x||=0$ or $||y||=0$, we set $s(x,y)=0$. Note that this measure always yields a value $s(x,y)\\in[-1,1]$. In the case that the vectors $x$ and $y$ only have positive entries, one has $s(x,y)\\in[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_template_matrix(templates):\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "\n",
    "To obtain a better understanding of this procedure, we continue our Beatles example from above. The following steps are performed:\n",
    "\n",
    "* First, the audio recording is converted into a chroma representation.\n",
    "* Second, each chroma vector is compared with each of the $24$ binary chord templates, which yields $24$ similarity values per frame. These similarity values are visualized in the form of a **time&ndash;chord representation**.\n",
    "* Third, we select for each frame the chord label $\\lambda_{n}$ of the template that maximizes the similarity value over all $24$ chord templates. This yields our final chord recognition result.\n",
    "\n",
    "The following figure additionally shows a visualization of the expected (ground-truth) chord labels, which may be used for evaluating our chord recognizer. Furthermore, the similarity-maximizing (normalized) chord templates are shown. In a way, this sequence of chord templates may be thought of as a musically informed quantization of the original chroma representation.\n",
    "\n",
    "<img src=\"data/img/letitbe.png\" width=\"600px\" align=\"middle\" alt=\"FMP_C5_F15\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Filtering\n",
    "In the previous lecture we have seen of to extract feature from audio recordings (in particular the chromagram).\n",
    "But feature extraction is not enough and **feature pre or post filtering** can be necessary. We are going to see how to **normalize** and **scale** and how to **smooth** the feautures for enhancing the chord extraction algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization\n",
    "\n",
    "In this application, the audio recording is transformed into a feature representation (chromagram). Often, these representations consists of a sequence $X=(x_1,x_2,\\ldots x_N)$ with feature vectors $x_n \\in  \\mathcal{F}=\\mathbb{R}^K$ for $n\\in[1:N]$. To better compare feature representations, one often applies **normalization**. One normalization strategy is to choose a suitable norm $p$ and then to replace each feature vector $x_n\\in\\mathcal{F}$ by $x_n/p(x_n)$. This strategy works as long as $x_n$ is a nonzero vector. Note that the normalized feature vector  $x_n/p(x_n)$ is a unit vector with regard to the norm $p$.\n",
    "\n",
    "Therefore, let's consider the case that $X=(x_1,x_2,\\ldots x_N)$ is a sequence of chroma features. In this case, the feature space $\\mathcal{F}=\\mathbb{R}^K$ has the dimension $K=12$. The normalization procedure as described above replaces each chroma vector by its normalized version. As a result, a normalized chroma vector only encodes **relative** rather than **absolute** differences in the sizes of the twelve chroma coefficients. Intuitively speaking, normalization introduces a kind of **invariance** to differences in **dynamics** or **sound intensity**.\n",
    "\n",
    "The normalization procedure is only possible if $p(x)\\not= 0$. Also for very small values $p(x)$, which may occur in passages of silence before the actual start of the recording or during long pauses, normalization would lead to more or less random and therefore meaningless chroma value distributions. Therefore, if $p(x)$ falls below a certain threshold, the vector $x$ may be replaced by some standard vector such as a uniform vector of norm one instead of dividing by $p(x)$.\n",
    "\n",
    "Mathematically, this normalization procedure can be described as follows. Let $S^{K-1}\\subset\\mathbb{R}^{K}$ be the unit sphere containing all $K$-dimensional vectors of norm one. Then, for a given threshold $\\varepsilon>0$, we define a projection operator $\\pi^{\\varepsilon}:\\mathbb{R}^{K}\\to S^{K-1}$ by\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi^{\\varepsilon}(x):=\n",
    "\\left\\{\\begin{array}{cl} x / p(x) & \\,\\,\\,\\mbox{if}\\,\\, p(x) > \\varepsilon\\\\\n",
    "          u & \\,\\,\\,\\mbox{if}\\,\\, p(x) \\leq \\varepsilon \\end{array}\\right.\n",
    "\\end{equation}\n",
    "\n",
    "where $u=v/p(v)$ is the unit vector of the all-one vector $v=(1,1,\\ldots,1)^\\top\\in\\mathbb{R}^K$. Based on this operator, each chroma vector $x$ can be replaced by $\\pi^{\\varepsilon}(x)$. The threshold $\\varepsilon$ is a parameter that needs to be chosen with care. A suitable choice will depend on the requirements of the application in mind. One can think of many variants for this normalization. Obviously, the normalization depends on the chosen norm and on the threshold. Furthermore, instead of taking the equally distributed unit vector $u$, one may take any another vector to represent feature vectors of small size. \n",
    "\n",
    "\n",
    "\n",
    "## Norms\n",
    "\n",
    "### Euclidean Norm\n",
    "\n",
    "The most commonly used norm is the **Euclidean norm** (or $\\ell^2$-norm). This norm is often denoted by $\\|\\cdot\\|_2$ and defined by\n",
    "\n",
    "$$\n",
    "   \\|x\\|_2 = \\sqrt{\\langle x\\mid x\\rangle} = \\Big(\\sum_{k=0}^{K-1} x(k)^2\\Big)^{1/2}\n",
    "$$\n",
    "\n",
    "for a vector $x=(x(0),x(1),\\ldots,x(K-1))^\\top \\in\\mathbb{R}^K$.  The Euclidean norm $\\|x\\|_2$  gives the usual distance from the origin $(0,0)$ to the point $x$. The set of unit vectors with regard to the Euclidean norm forms a **unit sphere** denoted as $S^{K-1}\\subset\\mathbb{R}^K$. In the case of $K=2$, the unit sphere is the unit circle $S^1$ with origin $(0,0)$. \n",
    "\n",
    "### Manhattan Norm\n",
    "\n",
    "In the **Manhattan norm** (or $\\ell^1$-norm), the length of a vector is measured by summing up the absolute values of the vector's Cartesian coordinates. The Manhattan norm, denoted $\\|\\cdot\\|_1$, is defined by \n",
    "\n",
    "$$\n",
    "   \\|x\\|_1 = \\sum_{k=0}^{K-1} |x(k)|\n",
    "$$\n",
    "\n",
    "for a vector $x=(x(0),x(1),\\ldots,x(K-1))^\\top \\in\\mathbb{R}^K$. The name of the norm comes from the grid-like layout of the streets in Manhattan, which forces a taxi to follow straight lines between the street's intersection points. In the Manhattan norm, the set of unit vectors forms a square with sides oriented at a $45$ degree angle to the coordinate axes. For the case $K=2$, the unit circle of the Manhattan norm is describe by $|x(1)| + |x(2)| = 1$.  \n",
    "\n",
    "### Maximum Norm\n",
    "\n",
    "In the **maximum norm** (or $\\ell^\\infty$-norm), the length of a vector is measured by its maximum absolute Cartesian coordinate. The maximum norm, denoted by $\\|\\cdot\\|_\\infty$, is defined by \n",
    "\n",
    "$$\n",
    "   \\|x\\|_\\infty = \\max\\big\\{|x(k)| \\,\\,\\mathrm{for}\\,\\, k\\in[0:K-1] \\big\\}\n",
    "$$\n",
    "\n",
    "for a vector $x=(x(0),x(1),\\ldots,x(K-1))^\\top \\in\\mathbb{R}^K$. The set of unit vectors forms the surface of a hypercube with edge length $2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature_sequence(X, norm='2', threshold=0.0001, v=None):\n",
    "    \"\"\"Normalizes the columns of a feature sequence\n",
    "\n",
    "    Args:\n",
    "        X: Feature sequence\n",
    "        norm: The norm to be applied. '1', '2', 'max'\n",
    "        threshold: An+ threshold below which the vector `v` used instead of normalization\n",
    "        v: Used instead of normalization below `threshold`. If None, uses unit vector for given norm\n",
    "\n",
    "    Returns:\n",
    "        X_norm: Normalized feature sequence\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Smoothing and Downsampling\n",
    "\n",
    "For certain music retrieval applications, these chromagrams may be too detailed. In particular, it may be desirable to further increase the similarity between them. \n",
    "\n",
    "We now show how this can be achieved by **smoothing procedures** applied in a postprocessing step. \n",
    "The idea is to compute for each chroma dimension a kind of local average over time. \n",
    "\n",
    "More precisely, let $X=(x_1,x_2, ..., x_N)$ be a feature sequence with $x_n\\in\\mathbb{R}^K$ for $n\\in[1:N]$, and let $w$ be a **rectangular window** $w$ of length $L\\in\\mathbb{N}$. Then we compute for each $k\\in[1:K]$ a convolution between $w$ and the sequence $(x_1(k), x_2(k),\\ldots, x_N(k))$. Assuming a centered view, we only keep the center part of length $N$ of the convolution. The result is a smoothed feature sequence of the same dimensions $K\\times N$.\n",
    "\n",
    "* In the following implementation, we use the function `scipy.signal.convolve` to compute a 2D convolution. Setting the dimension to $1\\times L$ for the **window** (also called **kernel**) results in a bandwise 1D convolution.\n",
    "* Using the parameter `mode='same'` enforces the centered view.\n",
    "* As for the window $w$, one may also use other window types such as a **Hann window**. \n",
    "\n",
    "Applying temporal smoothing using a rectangular or a Hann window can be regarded as bandwise  **lowpass filtering**, which attenuates fast temporal fluctuations in the feature representation. \n",
    "\n",
    "Often, to increase the efficiency of subsequent processing and analysis steps, one decimates the smoothed representation by keeping only every $D^\\mathrm{th}$ feature, where $D\\in\\mathbb{N}$ is a suitable constant (typically much smaller than the window length $L$). This decimation, which is also referred to as **downsampling**, reduces the feature rate by a factor $D$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def smooth_downsample_feature_sequence(X, Fs, filt_len=41, down_sampling=10, w_type='boxcar'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X: Feature sequence\n",
    "        Fs: Frame rate of `X`\n",
    "        filt_len: Length of smoothing filter\n",
    "        down_sampling: Downsampling factor\n",
    "        w_type: Window type of smoothing filter\n",
    "\n",
    "    Returns:\n",
    "        X_smooth: Smoothed and downsampled feature sequence\n",
    "        Fs_feature: Frame rate of `X_smooth`\n",
    "        \n",
    "    Hint: use numpy expand dims to obtain a window of dimension (1, L)\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application we are going to use **feature normalization** only, but in the future we are going to need feature smoothing too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template-base chord recognition implementation\n",
    "\n",
    "As already mentioned, for comparing chroma features and chord templates, we use a simple **similarity measure** using the inner product of normalized vectors:\n",
    "\n",
    "\\begin{equation}\n",
    "  s(x,y)= \\frac{\\langle x,y\\rangle}{||x||\\cdot||y||}\n",
    "\\end{equation}\n",
    "\n",
    "for $x,y\\in\\mathcal{F}\\setminus\\{0\\}$. In the case $||x||=0$ or $||y||=0$, we set $s(x,y)=0$. Note that this measure always yields a value $s(x,y)\\in[-1,1]$. In the case that the vectors $x$ and $y$ only have positive entries, one has $s(x,y)\\in[0,1]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
